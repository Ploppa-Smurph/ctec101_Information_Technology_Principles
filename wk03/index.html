<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CTEC-101 IT Fundamentals - Wk 03 - Introduction to Computers</title>
</head>

<body>
    <h1>CTEC-101 IT Fundamentals - Wk 03 - Introduction to Computers</h1>
    <a href="https://labsimapp.testout.com/v6_0_480/index.html/productviewer/1184/2.2/3c4cd191-2f13-42f2-af50-2378de42d4f7">link to Chapter 2</a>
    <h2>2.2 - Key Terms</h2>
    <ul>
        <li><b>Input</b> - information entered into a computer by pressing a key on a keyboard, clicking a mouse, tapping a touchscreen, pushing a button on a controller, etc... </li>
        <li><b>Processing</b> - operations performed by a computer to retrieve, transform, or classify information</li>
        <li><b>Output</b> - information that a computer returns to a user such as images on a screen, sounds from speakers, and printed pages.</li>
        <li><b>Storage</b> - saving of information on memory chips, discs, or other storage media for later use</li>
        <li><b>Hollerith's Tabulating Machine</b> - early computing machine that used punch cards and metal-pins; used to compile the 1890's census</li>
        <li><b>Transistor</b> - smaller, faster, cheaper and more durable electronic device that replaced mechanical relays which were slow and tended to wear down over time</li>
        <li><b>Microchip</b> - electronic device that allowed entire computers to be built into a single board, replacing modules for each part of the computer. Microchips paved the way for PC ownership.</li>
        <li><b>World Wide Web</b> - system for making digital resources publicly available over the internet using a browser that paved the way for email, chatrooms, and social media.</li>
        <li><b>Smartphone</b> - mobile phone that functions as a computer and allows users to access the internet</li>
        <li><b>Supercomputers</b> - fastest, most powerful computers that exist at a given time. These 'Supercomputers' have processing capabilities designed to solve problems that are too complex for regular computers. They play vital roles in the advancement
            of national defense, science, and social change.</li>
        <li><b>Human-Computer Interaction</b> - field of study that looks at how computers and other kinds of technology interact with humans.</li>
    </ul>

    we live in the information age and with the advent of computers we have shifted from traditional industry into information technology.
    <br> computers, at their most basic level: take input from user, process the information, and then output, or store, the results.
    <h4> 2.2.2 - Computer Functions</h4>
    <b>Input</b> - before a computer can work it needs input from a user. input is the act of physically putting data into a computer. inputs are often used to send commands to the software application that in turns stores data in 'system memory', aka
    Random Access Memory (RAM). Input
    <br><br><b>Data Processing</b> - when input is received the operating system in the computer performs calculations on the input and converts the raw electrical signals into information that can be used.
    <br>The information is often stored in RAM. Data Processing occurs when the CPU retrieves the information from RAM and manipulates it according to instructions from an application. After processing is complete the changed info is stored in RAM.
    <br><br><b>Output</b> - 1 option that a computer has to deal with the data returned to the user - as an image on a screen, sound through speakers, or pages to a printer.
    <br><br><b>Storage</b> - a 2nd option for dealing with data, save it to physical memory to deal with later.
    <h4>2.2.3 - History of Computers</h4>
    Herman Hollerith made the first "Tabulating Machine" to compile the census data in 1890. It was a punch card machine. Hollerith's company later became IBM (International Business Machines).
    <br>pre 1947 computers were very large and relied on Vacuum Tubes to relay information through the system. in 1947 Bell Labs created Transistors
    <br>Transistors were able to replace the bulky Vacuum tubes. Transistors were made of Silicon and started production in California's Santa Clara Valley, that is why the area is known as Silicone Valley.
    <br>in 1959, Jack Kilby invented the microchip. microchips allowed computers to be produced on a single board as opposed to a room full of equipment and paved the way for Personal Computers.
    <br>in 1977 3 successful Personal Computers were released: Apple 2, TRS 80, and the Commodore Pet(??) 2001. 4 years later IBM came out with the PC.
    <br>at first the PCs were mostly used for work, especially for word processing. In the early 80's the popularity of Video Games led to the rise of Arcades.
    <br>wordprocessing remained the primary use for personal computers until the mid-90's when the World Wide Web became popular.
    <br>the internet was huge, but relied on access to desktop or laptop computers until 2007 when Apple released the 1st Smartphone, the Apple IPhone.
    <br>most telephones sold today are smartphones (which are small, powerful computers).
    <h4>2.2.4 - Computer Facts</h4>
    </p>
    <p>Table 1: Timeline of Important Events in Computer History
        <br>
        <br> <b>1890</b> - Hollerith's Tabulating Machine At the end of the 19th century, the population of the United States was rapidly growing. Because there were so many people, the 1880 census took seven years to compile, and it was predicted that
        the 1890 census would take nearly twice as long. To solve this problem, the government hired Herman Hollerith to devise a solution. Hollerith created an electromechanical tabulating machine to process the census data. It worked by punching data
        into paper cards, then inserting them into the machine. Inside the machine, small metal pins would pass through the holes into a vial of mercury, completing an electrical circuit. This in turn powered an electric motor, which turned the appropriate
        gear in the machine to keep track of the count. Using this machine, the entire census was compiled in two and a half years.
        <br> <b>1944</b> - Harvard Mark 1 Completed Working together, engineers from Harvard University and IBM created the Harvard Mark 1, which at the time was the most powerful computing machine ever built. It was fifty feet long, weighed five tons,
        and was built from about 750,000 individual mechanical parts. The Mark 1 was used by the Allies during World War II and assisted in creating simulations for the Manhattan Project. It could perform three additions or subtractions every second and
        one multiplication every six seconds.
        <br> <b>1947</b> - First Transistor Developed Early computers sent signals via mechanical relays. Relays were metal switches that would physically move to make and break electrical circuits, representing 1s and 0s. Because the parts had to physically
        move, they were slow and tended to wear down over time. In 1947, scientists at Bell Laboratories invented the transistor. Transistors contain silicon, a semiconductor that can be made to sometimes conduct electricity and sometimes not. Because
        they didn't have any moving parts, silicon transistors were smaller, faster, cheaper, and more durable than mechanical relays.
        <br> <b>1959</b> - Invention of the Microchip Throughout the 1950s, computers were large and expensive. Most computers were owned by governments, universities, and businesses - they had no place in the typical home. Then, in 1959, researchers
        at Texas Instruments developed an integrated circuit, or microchip. This new technology allowed an entire computer to be built into a single board, rather than needing large modules for each part of the computer. Microchips paved the way for personal
        computer ownership.
        <br> <b>1977</b> - The Personal Computer Revolution In 1977, three successful personal computers were released to the public: The Apple II, the TRS-80 Model 1, and the Commodore Pet 2001. These three computers became known as the "1977 trinity."
        1977 also saw the release of the Atari 2600, the first popular home video game console. For the first time, computers were marketed to the general public rather than just businesses and hobbyists. Four years later, IBM followed up with the IBM
        PC, giving birth to the PC/Apple rivalry that still exists today.
        <br> <b>1994</b> - The World Wide Web Personal computer ownership began to skyrocket in the mid-nineties with the advent and rise of the World Wide Web, which began in 1991. In 1994, the web became public, and the world got a lot smaller. With
        new technology like email and chatrooms, computers became a viable way of communicating with other people and thus became more popular. In the early 2000s, social media sites like MySpace and Facebook were launched.
        <br> <b>2007</b> - Smart Phones Through the mid 2000s, Internet access was mostly limited to computers and laptops. Then, in 2007, Apple unveiled the iPhone, the world's first smartphone. Now, people could access the Internet anywhere. Smartphones
        are now extremely common in the developed world, almost completely replacing other kinds of personal telephones.
    </p>
    <h4>2.2.5 - Supercomputers</h4>
    the fastest, most powerful computers that exist at a given time.
    <p><b>Naval Ordnance Research Calculator</b> in 1954 IBM created the first Supercomputer called NORC (Naval Ordnance Research Calculator).
        <br>it was the most powerful computer on earth from 1954 - 1963 with the power to store 2,000 words in it's electrostatic memory tubes. It had a access time of 8 microseconds
        <br>NORC ended up in Dahlgren, Virginia and at it's presentation ceremony on December 2nd, 1954 NORC calculated Pi to 3,089 digits in 13 minutes, which was a record at the time.</p>
    <p><b>CDC600 and CDC7600</b> in 1965 Seymour Cray @ Control Data Corporation built the CDC600 which could execute 3,000,000 instructions per second - 10x faster than any computer at the time.
        <br>in 1967 the successor, CDC7600 was built. CDC7600 used 'Pipelining', which is the ability to run several states of an instruction at the same time to increase performance.
        <br> the 7600 was 10x faster than the 6600 and was regarded as the fastest computer in the world at the time. it was still reported to break down once a day.
    </p>
    <p><b>ILLIAC IV</b> in 1964 the Defense Advanced Research Projects Agency (DARPA) founded a project at the University of Illinois called ILLIAC IV
        <br>the project was completed in 1972 and was the first to use Solid State Memory. ILLIAC IV was the first network-available supercomputer. On September 7th, 1981, after 10 years in operation, the ILLIAC IV was turned off.
    </p>
    <p><b>Cray Research, Inc</b> in 1972 Seymour Cray left CDC and opened Cray Research in his home in Chippewa Falls, Wisconsin.
        <br>The Cray-1 was built in 1975 and boasted world-record speeds of 160 megaflops and had 8mb of main memory. It was a Vector Computer with only one main processor that was optimized to do the same instruction on several pieces of data.
        <br> Cray Research is still around and made breakthroughs throughout the 90's. Cray has partnered with AMD to create 'Frontier' the world's fastest supercomputer (to be completed in 2022)
    </p>
    <h4>2.2.6 - Human-Computer Interaction</h4>
    Human-Computer Interaction (HCI) is a field of study that looks at how computers and other technology interact with humans.
    <br> Focus on User-Centered Design (UCD), a process where the Design team takes on the needs of the end user at every phase of the process. UCD products are as accessible as possible.
    <br> HCI also informs User Interface (UI) which is a design process that concentrates mainly on the look or style of a program. UI seeks to create a visual experience for the user that will be simple to use, enjoyable to look at, and meaningful.
    <br> ex: a software company is developing a word processing program - they would need to think about an interface style that was simple and intuitive while still offering the features that users are looking for. you need editing tools, multimedia
    support, and secure backups.
    <br> the development team will take into account the details like making certain the interface isn't overwhelming and that fonts are large enough.
    <p>the Questions of Human-Computer Interaction
        <br><br> 1. Why are people using computers? what motivates them and what do they value?

        <br><br> 2. What do people want to do with computers? what functionality and features do they need?

        <br><br> 3. How are people using computers? how can they access what they want? what sort of aesthetics do they expect?
        <h5>Principles for Measuring Human-Computer Interaction</h5>
        <ul>
            <li><b>Usability</b> - refers to how suitable the computer is for the task and how easy it is to learn</li>
            <li><b>Effectiveness</b> - what percentage of a goal the computer is able to achieve. How good is the computer at doing the task that needs to be accomplished?</li>
            <li><b>Efficiency</b> - how much time it takes the computer to complete a task. also looks at how much time the user has to take correcting errors.</li>
            <li><b>Satisfaction</b> - how happy the user is with how the computer functioned. was the user satisfied with each step of the process?</li>
        </ul>
    </p>
    <h2>2.3 - Digital Data</h2>
    Key Terms:
    <ul>
        <li><b>Decimal System</b> - numbering system that uses ten digits, 0-9</li>
        <li><b>Binary System</b> - numbering system with two digits, 0 and 1</li>
        <li><b>Hexadecimal System</b> - numbering system with sixteen digits, 0-9 and A through F</li>
        <li><b>Bit</b> - the smallest unit of digital information, represented by 1 or 0</li>
        <li><b>Byte</b> - group of 8 bits joined together</li>
        <li><b>Digital Data</b> - physical signal, such as text, number, graphic, or sound, interpreted by converting it into binary numbers</li>
        <li><b>Encoded Integers</b> - representation for integers using a group of bytes. Normally, one bit in one of the bytes represents the sign, 1 for negative and 0 for positive. the remaining 31 bits are used to encode the number itself using binary
            digits
        </li>
        <li><b>Encoded Text</b> - representation of text by assigning a unique binary code to each character</li>
        <li><b>Processor Speed</b> - speed at which the computer can process information as measured by the number of cycles per second (Hertz) that the computer CPU operates at. Processor Speed is measured in Kilohertz, Megahertz, or Gigahertz</li>
        <li><b>Storage Space</b> - measurement in bytes of the volume of storage a device contains. Measured in kilobytes (1024 bytes), megabytes (1024 kilobytes), gigabytes (1024 megabytes), and terabytes (1024 gigabytes)</li>
        <li><b>Throughput</b> - measurement in bits per second that information is transferred through a network from one computer to another. Measured in Kbps (kilobits/second), Mbps (megabits/second), and Gbps (gigabits/second) </li>
        <li><b>ASCII</b> - American Standard Code for Information Interchange. unique 7-bit binary code to represent characters on the internet. Extended ASCII uses 8-bit binary code for international characters</li>
        <li><b>Unicode</b> - International 16-bit encoding standard that accommodates character sets from multiple languages</li>
    </ul>
    8-bit graphics are limited to 256 colors since 1 byte has 256 combinations. computers today run on 32 or 64 bit architecture, meaning 32bit systems have almost 4.3 billion combinations, and 64bit uses the 24bit color and 8bit of z-buffer data (alpha transparency)
    <br>4,294,967,295 is the possible amount of character combinations in 32bit systems, that is equal to 32 1s in binary. in binary in order to tell if an integer is positive or negative the first bit of data is marked as 0 = positive, or 1 = negative.
    this gives a range of -2.1 billion to +2.1 billion
    <p>computers interpret digital signals as 1 and 0 - that is a single bit of information. 8 bits of data form 1 byte.
        <br>bits can be used to represent text and numbers with binary code. we then discussed units of measure for Storage, Throughput, and Processing Speed</p>
    <h3>2.3.4 - Digital Information Facts</h3>
    Computers work by translating physical signals, such as electrical charges into digital information.<br>
    <ul>
        <li><b>Bit</b> - smallest unit of digital information - each 1 or 0 in a binary sequence is 1 bit</li>
        <li><b>Byte</b> - 8 bits form a byte -- the value of a byte can range from 0 (eight 0s) to 255 (eight 1s)</li>
        <li><b>Kilobyte (KB)</b> - one Kilobyte is equal to 1024 bytes</li>
        <li><b>Megabyte (MB)</b> - one Megabyte equals 1024 Kilobytes, or 1 million bytes</li>
        <li><b>Gigabyte (GB)</b> - one billion bytes, or 1024 Megabytes</li>
        <li><b>Terabyte (TB)</b> - 1024 Gigabytes, or a trillion bytes</li>
        <li><b>Digital Data</b> - a physical signal such as text, number, graphic, or sound - interpreted by converting into binary numbers</li>
        <li><b>Encoding Integers</b> - since integers have a positive or negative value computers encode 32bit by using the first bit for the sign, 0 = positive and 1 = negative. the remaining 31 bits are used to encode the number. there is a range of -2.1
            billion to +2.1 billion </li>
        <li><b>Encoding Text</b> - computers encode text by assigning a unique binary code to each character</li>
        <li><b>Processing Speed</b> - 64 bit processors computers can receive or send 8 bytes of data at once. Each time the processor writes to memory or reads data from memory is a cycle. the base unit is the hertz (Hz). 1 hertz is 1 cycle / second<br>            1 kilohertz (KHz) = 1000 Hz; 1 megahertz (MHz) = 1 million HZ - seen on older PC Bus interfaces; 1 gigahertz (GHz) = 1 billion Hz </li>
        <li><b>Storage Space</b> - </li>
        <li><b>Throughput</b> - </li>
        <li><b>System Memory</b> - </li>
    </ul>

</body>

</html>